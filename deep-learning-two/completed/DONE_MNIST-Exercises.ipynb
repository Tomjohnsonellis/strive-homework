{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Bunch of imports and setup\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "# Train and test loader\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
    "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "112.7%\n",
      "/home/tom/anaconda3/envs/poggers/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\\\"background:#222222; color:#ffffff; padding:20px\\\">\n",
    "      <h3 style=\\\"color:#01ff84; margin-top:4px\\\">Exercise 1:</h3>\n",
    "      <p>Now it's your turn to build a simple network, use any method I've covered so far. In the next notebook, you'll learn how to train a network so it can make good predictions.</p>\n",
    "      <p>Build a network to classify the MNIST images with 3 hidden layers. Use 16 units in the first hidden layer, 32 units in the second layer, and 8 units in the third layer. Each hidden layer should have a ReLU activation function, and use softmax on the output layer.</p>\n",
    "    <div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "input_size = 784\n",
    "hidden_sizes =  [16, 32, 8]\n",
    "output_size = 10\n",
    "model = nn.Sequential(\n",
    "        OrderedDict([\n",
    "            ('First_Layer', nn.Linear(input_size, hidden_sizes[0])),\n",
    "            ('First_ReLU', nn.ReLU()),\n",
    "            ('Second_Layer', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "            ('Second_ReLU', nn.ReLU()),\n",
    "            ('Third_Layer', nn.Linear(hidden_sizes[1], hidden_sizes[2])),\n",
    "            ('Third_ReLU', nn.ReLU()),\n",
    "            ('Output_Layer', nn.Linear(hidden_sizes[2], output_size)),\n",
    "            ('Output_ReLU', nn.ReLU()),\n",
    "            ('Softmax_Output', nn.Softmax(dim=1)),\n",
    "            # I think the above works? if not:\n",
    "            # ('Softmax_Output', F.softmax(dim=1)),\n",
    "        ])\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Run this cell with your model to make sure it works\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\\\"background:#222222; color:#ffffff; padding:20px\\\">\n",
    "      <h3 style=\\\"color:#01ff84; margin-top:4px\\\">Exercise 2:</h3>\n",
    "      <p>Train your network implementing the Pytorch training loop and <strong style=\\\"color:#01ff84\\\">after each epoch, use the model for predicting the test (validation) MNIST data.</strong></p>\n",
    "      <p>Note: If your model does not fit with the final softmax layer, you can remove this layer.</p>\n",
    "      <p>Hint: <a href=\\\"https://discuss.pytorch.org/t/training-loop-checking-validation-accuracy/78399\\\">Training loop checking validation accuracy\n",
    "    </a></p>\n",
    "      <p>Research about <code>model.train()</code>, <code>model.eval()</code> and <code>with torch.no_grad()</code> in Pytorch.\n",
    "    <div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "## TODO: Your training loop here\n",
    "input_size = 784\n",
    "hidden_sizes =  [128, 64]\n",
    "output_size = 10\n",
    "model = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ('First_Layer', nn.Linear(input_size, hidden_sizes[0])),\n",
    "        ('First_ReLU', nn.ReLU()),\n",
    "        ('Second_Layer', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "        ('Second_ReLU', nn.ReLU()),\n",
    "        ('Final_Layer', nn.Linear(hidden_sizes[1], output_size)),\n",
    "        ('Final_ReLU', nn.ReLU())\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Model parameters\n",
    "optimiser = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "training_epochs = 3\n",
    "print_every = 500 # Just so we have a manageable amount of text displayed\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch {epoch+1} / {training_epochs}\")\n",
    "\n",
    "    for cycle, (images, labels) in enumerate(iter(trainloader)):\n",
    "        # Flatten the images for our network\n",
    "        images = images.reshape(16, 784)\n",
    "        # Zero out the gradients\n",
    "        optimiser.zero_grad()\n",
    "        # Make a guess by passing an image forward through the network\n",
    "        model_guess = model.forward(images)\n",
    "        # Calculate how good/bad that guess is\n",
    "        loss_value = criterion(model_guess, labels)\n",
    "        # Backpropogate to see how we need to adjust the weights\n",
    "        loss_value.backward()\n",
    "        # Adjust the weights\n",
    "        optimiser.step()\n",
    "\n",
    "        # Keep track of the loss for our human eyes to see\n",
    "        running_loss += loss_value.item()\n",
    "\n",
    "        if cycle % print_every == 0:\n",
    "            print(f\"Training cycle: {cycle}\\t Avg. Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0\n",
    "\n",
    "    # Eval loop here\n",
    "    # Eval Loop\n",
    "    # There are 10,000 samples in the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct_guesses = 0\n",
    "        for test_images, test_labels in iter(testloader):\n",
    "            test_images = test_images.reshape(16, 784)\n",
    "            test_guess = model.forward(test_images)\n",
    "            loss_value = criterion(test_guess, test_labels)\n",
    "            # print(\"=\"*50)\n",
    "            # print(f\"Model predicions are this size: {test_guess.size()}\")\n",
    "            index = 0\n",
    "            for guess in test_guess:\n",
    "\n",
    "                # print(\"I am the guess values for one image\")\n",
    "                guess = F.softmax(guess, dim=1)\n",
    "                # print(guess)\n",
    "                prediction = 0\n",
    "                for value in guess:\n",
    "                    if value == guess.max():\n",
    "                        break\n",
    "                    else:\n",
    "                        prediction += 1\n",
    "                # print(f\"My prediction is: {prediction}\")\n",
    "                # print(f\"Actual value: {test_labels[index]}\")\n",
    "\n",
    "                if prediction == test_labels[index]:\n",
    "                    correct_guesses += 1\n",
    "                index += 1\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Correct Guesses: {correct_guesses} / 10,000\")\n",
    "        accuracy = correct_guesses / 100\n",
    "        print(f\"Accuracy: {accuracy}%\")\n",
    "        print(\"=\"*50)\n",
    "        model.train()\n",
    "\n",
    "print(\"*\"*50)\n",
    "print(\"DONE\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 / 3\n",
      "Training cycle: 0\t Avg. Loss: 0.0046\n",
      "Training cycle: 500\t Avg. Loss: 1.9237\n",
      "Training cycle: 1000\t Avg. Loss: 1.1629\n",
      "Training cycle: 1500\t Avg. Loss: 0.8964\n",
      "Training cycle: 2000\t Avg. Loss: 0.8203\n",
      "Training cycle: 2500\t Avg. Loss: 0.7901\n",
      "Training cycle: 3000\t Avg. Loss: 0.7860\n",
      "Training cycle: 3500\t Avg. Loss: 0.7508\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tom\\AppData\\Local\\Temp/ipykernel_7256/2452867569.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  guess = F.softmax(guess)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================================================\n",
      "Correct Guesses: 7393 / 10,000\n",
      "Accuracy: 0.7393\n",
      "==================================================\n",
      "Epoch 2 / 3\n",
      "Training cycle: 0\t Avg. Loss: 0.0006\n",
      "Training cycle: 500\t Avg. Loss: 0.7523\n",
      "Training cycle: 1000\t Avg. Loss: 0.6493\n",
      "Training cycle: 1500\t Avg. Loss: 0.5243\n",
      "Training cycle: 2000\t Avg. Loss: 0.4969\n",
      "Training cycle: 2500\t Avg. Loss: 0.4834\n",
      "Training cycle: 3000\t Avg. Loss: 0.4809\n",
      "Training cycle: 3500\t Avg. Loss: 0.4834\n",
      "==================================================\n",
      "Correct Guesses: 8451 / 10,000\n",
      "Accuracy: 0.8451\n",
      "==================================================\n",
      "Epoch 3 / 3\n",
      "Training cycle: 0\t Avg. Loss: 0.0004\n",
      "Training cycle: 500\t Avg. Loss: 0.4381\n",
      "Training cycle: 1000\t Avg. Loss: 0.4428\n",
      "Training cycle: 1500\t Avg. Loss: 0.4461\n",
      "Training cycle: 2000\t Avg. Loss: 0.4318\n",
      "Training cycle: 2500\t Avg. Loss: 0.4297\n",
      "Training cycle: 3000\t Avg. Loss: 0.4165\n",
      "Training cycle: 3500\t Avg. Loss: 0.4044\n",
      "==================================================\n",
      "Correct Guesses: 8599 / 10,000\n",
      "Accuracy: 0.8599\n",
      "==================================================\n",
      "**************************************************\n",
      "DONE\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Eval Loop\n",
    "# There are 10,000 samples in the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct_guesses = 0\n",
    "    for test_images, test_labels in iter(testloader):\n",
    "        test_images = test_images.reshape(16, 784)\n",
    "        test_guess = model.forward(test_images)\n",
    "        loss_value = criterion(test_guess, test_labels)\n",
    "        # print(\"=\"*50)\n",
    "        # print(f\"Model predicions are this size: {test_guess.size()}\")\n",
    "        index = 0\n",
    "        for guess in test_guess:\n",
    "\n",
    "            # print(\"I am the guess values for one image\")\n",
    "            guess = F.softmax(guess, dim=1)\n",
    "            # print(guess)\n",
    "            prediction = 0\n",
    "            for value in guess:\n",
    "                if value == guess.max():\n",
    "                    break\n",
    "                else:\n",
    "                    prediction += 1\n",
    "            # print(f\"My prediction is: {prediction}\")\n",
    "            # print(f\"Actual value: {test_labels[index]}\")\n",
    "\n",
    "            if prediction == test_labels[index]:\n",
    "                correct_guesses += 1\n",
    "            index += 1\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Correct Guesses: {correct_guesses} / 10,000\")\n",
    "    accuracy = correct_guesses / 100\n",
    "    print(f\"Accuracy: {accuracy}%\")\n",
    "    print(\"=\"*50)\n",
    "model.train()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tom\\AppData\\Local\\Temp/ipykernel_7256/855075697.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  guess = F.softmax(guess)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================================================\n",
      "Correct Guesses: 9453 / 10,000\n",
      "Accuracy: 0.9453\n",
      "==================================================\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 3:</h3>\n",
    "  <p>Write the code for adding <strong style=\"color:#01ff84\">Early Stopping with patience = 2</strong> to the training loop from scratch.</p>\n",
    "  <p><strong style=\"color:#01ff84\">Hint:</strong> Monitor the Validation loss every epoch, and if in 2 epochs, the validation loss does not improve, stop the training loop with <code>break</code>.</p>\n",
    "<div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\"\"\"\n",
    "For this exercise, we need to keep track of the loss in each epoch, and stop the training process if the algorithm isn't improving\n",
    "\n",
    "\"\"\"\n",
    "# Copied from above\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes =  [128, 64]\n",
    "output_size = 10\n",
    "model = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ('First_Layer', nn.Linear(input_size, hidden_sizes[0])),\n",
    "        ('First_ReLU', nn.ReLU()),\n",
    "        ('Second_Layer', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "        ('Second_ReLU', nn.ReLU()),\n",
    "        ('Final_Layer', nn.Linear(hidden_sizes[1], output_size)),\n",
    "        ('Final_ReLU', nn.ReLU())\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Model parameters\n",
    "optimiser = optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "training_epochs = 100\n",
    "print_every = 1000 # Just so we have a manageable amount of text displayed\n",
    "previous_loss = 0\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch {epoch+1} / {training_epochs}\")\n",
    "\n",
    "    for cycle, (images, labels) in enumerate(iter(trainloader)):\n",
    "        # Flatten the images for our network\n",
    "        images = images.reshape(16, 784)\n",
    "        # Zero out the gradients\n",
    "        optimiser.zero_grad()\n",
    "        # Make a guess by passing an image forward through the network\n",
    "        model_guess = model.forward(images)\n",
    "        # Calculate how good/bad that guess is\n",
    "        loss_value = criterion(model_guess, labels)\n",
    "        # Backpropogate to see how we need to adjust the weights\n",
    "        loss_value.backward()\n",
    "        # Adjust the weights\n",
    "        optimiser.step()\n",
    "\n",
    "        # Keep track of the loss for our human eyes to see\n",
    "        running_loss += loss_value.item()\n",
    "\n",
    "        if cycle % print_every == 0:\n",
    "            print(f\"Training cycle: {cycle}\\t Avg. Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0\n",
    "\n",
    "    # Eval loop here\n",
    "    # Eval Loop\n",
    "    # There are 10,000 samples in the test set\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_images, test_labels in iter(testloader):\n",
    "            test_images = test_images.reshape(16, 784)\n",
    "            test_guess = model.forward(test_images)\n",
    "            loss_value = criterion(test_guess, test_labels)\n",
    "            epoch_loss += loss_value\n",
    " \n",
    "        print(\"=\"*50)\n",
    "        print(f\"Loss this validation epoch: {epoch_loss}\")\n",
    "        if previous_loss != 0:\n",
    "            print(f\"Previous loss: {previous_loss}\")\n",
    "            if previous_loss <= epoch_loss:\n",
    "                print(\"Model is not improving, exiting...\")\n",
    "                print(\"@\"*50)\n",
    "                break\n",
    "        previous_loss = epoch_loss\n",
    "        model.train()\n",
    "\n",
    "print(\"*\"*50)\n",
    "print(\"DONE\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0046\n",
      "Training cycle: 500\t Avg. Loss: 2.0051\n",
      "Training cycle: 1000\t Avg. Loss: 1.3252\n",
      "Training cycle: 1500\t Avg. Loss: 1.1044\n",
      "Training cycle: 2000\t Avg. Loss: 1.0250\n",
      "Training cycle: 2500\t Avg. Loss: 0.8694\n",
      "Training cycle: 3000\t Avg. Loss: 0.7977\n",
      "Training cycle: 3500\t Avg. Loss: 0.7592\n",
      "==================================================\n",
      "Loss this validation epoch: 448.1414489746094\n",
      "Epoch 2 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0021\n",
      "Training cycle: 500\t Avg. Loss: 0.7141\n",
      "Training cycle: 1000\t Avg. Loss: 0.7117\n",
      "Training cycle: 1500\t Avg. Loss: 0.7102\n",
      "Training cycle: 2000\t Avg. Loss: 0.6936\n",
      "Training cycle: 2500\t Avg. Loss: 0.6983\n",
      "Training cycle: 3000\t Avg. Loss: 0.6926\n",
      "Training cycle: 3500\t Avg. Loss: 0.6664\n",
      "==================================================\n",
      "Loss this validation epoch: 405.9627685546875\n",
      "Previous loss: 448.1414489746094\n",
      "Epoch 3 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0007\n",
      "Training cycle: 500\t Avg. Loss: 0.6371\n",
      "Training cycle: 1000\t Avg. Loss: 0.6578\n",
      "Training cycle: 1500\t Avg. Loss: 0.6461\n",
      "Training cycle: 2000\t Avg. Loss: 0.6424\n",
      "Training cycle: 2500\t Avg. Loss: 0.6258\n",
      "Training cycle: 3000\t Avg. Loss: 0.6231\n",
      "Training cycle: 3500\t Avg. Loss: 0.6161\n",
      "==================================================\n",
      "Loss this validation epoch: 380.94354248046875\n",
      "Previous loss: 405.9627685546875\n",
      "Epoch 4 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0011\n",
      "Training cycle: 500\t Avg. Loss: 0.5913\n",
      "Training cycle: 1000\t Avg. Loss: 0.6044\n",
      "Training cycle: 1500\t Avg. Loss: 0.6127\n",
      "Training cycle: 2000\t Avg. Loss: 0.6018\n",
      "Training cycle: 2500\t Avg. Loss: 0.6028\n",
      "Training cycle: 3000\t Avg. Loss: 0.5773\n",
      "Training cycle: 3500\t Avg. Loss: 0.6119\n",
      "==================================================\n",
      "Loss this validation epoch: 364.2335510253906\n",
      "Previous loss: 380.94354248046875\n",
      "Epoch 5 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0016\n",
      "Training cycle: 500\t Avg. Loss: 0.5911\n",
      "Training cycle: 1000\t Avg. Loss: 0.5643\n",
      "Training cycle: 1500\t Avg. Loss: 0.5651\n",
      "Training cycle: 2000\t Avg. Loss: 0.5711\n",
      "Training cycle: 2500\t Avg. Loss: 0.5859\n",
      "Training cycle: 3000\t Avg. Loss: 0.5806\n",
      "Training cycle: 3500\t Avg. Loss: 0.5825\n",
      "==================================================\n",
      "Loss this validation epoch: 354.4239196777344\n",
      "Previous loss: 364.2335510253906\n",
      "Epoch 6 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0010\n",
      "Training cycle: 500\t Avg. Loss: 0.5674\n",
      "Training cycle: 1000\t Avg. Loss: 0.5777\n",
      "Training cycle: 1500\t Avg. Loss: 0.5443\n",
      "Training cycle: 2000\t Avg. Loss: 0.5610\n",
      "Training cycle: 2500\t Avg. Loss: 0.5603\n",
      "Training cycle: 3000\t Avg. Loss: 0.5529\n",
      "Training cycle: 3500\t Avg. Loss: 0.5592\n",
      "==================================================\n",
      "Loss this validation epoch: 353.0208740234375\n",
      "Previous loss: 354.4239196777344\n",
      "Epoch 7 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0007\n",
      "Training cycle: 500\t Avg. Loss: 0.5537\n",
      "Training cycle: 1000\t Avg. Loss: 0.5606\n",
      "Training cycle: 1500\t Avg. Loss: 0.5502\n",
      "Training cycle: 2000\t Avg. Loss: 0.5405\n",
      "Training cycle: 2500\t Avg. Loss: 0.5381\n",
      "Training cycle: 3000\t Avg. Loss: 0.5261\n",
      "Training cycle: 3500\t Avg. Loss: 0.4587\n",
      "==================================================\n",
      "Loss this validation epoch: 237.44361877441406\n",
      "Previous loss: 353.0208740234375\n",
      "Epoch 8 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0017\n",
      "Training cycle: 500\t Avg. Loss: 0.3347\n",
      "Training cycle: 1000\t Avg. Loss: 0.3430\n",
      "Training cycle: 1500\t Avg. Loss: 0.3460\n",
      "Training cycle: 2000\t Avg. Loss: 0.3238\n",
      "Training cycle: 2500\t Avg. Loss: 0.3389\n",
      "Training cycle: 3000\t Avg. Loss: 0.3346\n",
      "Training cycle: 3500\t Avg. Loss: 0.3312\n",
      "==================================================\n",
      "Loss this validation epoch: 203.9017791748047\n",
      "Previous loss: 237.44361877441406\n",
      "Epoch 9 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0009\n",
      "Training cycle: 500\t Avg. Loss: 0.3184\n",
      "Training cycle: 1000\t Avg. Loss: 0.3190\n",
      "Training cycle: 1500\t Avg. Loss: 0.3232\n",
      "Training cycle: 2000\t Avg. Loss: 0.3122\n",
      "Training cycle: 2500\t Avg. Loss: 0.3003\n",
      "Training cycle: 3000\t Avg. Loss: 0.3210\n",
      "Training cycle: 3500\t Avg. Loss: 0.3355\n",
      "==================================================\n",
      "Loss this validation epoch: 203.2626190185547\n",
      "Previous loss: 203.9017791748047\n",
      "Epoch 10 / 10\n",
      "Training cycle: 0\t Avg. Loss: 0.0008\n",
      "Training cycle: 500\t Avg. Loss: 0.3065\n",
      "Training cycle: 1000\t Avg. Loss: 0.3250\n",
      "Training cycle: 1500\t Avg. Loss: 0.3053\n",
      "Training cycle: 2000\t Avg. Loss: 0.3198\n",
      "Training cycle: 2500\t Avg. Loss: 0.2970\n",
      "Training cycle: 3000\t Avg. Loss: 0.3004\n",
      "Training cycle: 3500\t Avg. Loss: 0.3074\n",
      "==================================================\n",
      "Loss this validation epoch: 204.0926971435547\n",
      "Previous loss: 203.2626190185547\n",
      "Model is not improving, exiting...\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "**************************************************\n",
      "DONE\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('poggers': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "f80c954d01f95c2ad67b8d0a560a05c6c6b2e66af80807006ce2befdd416022b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
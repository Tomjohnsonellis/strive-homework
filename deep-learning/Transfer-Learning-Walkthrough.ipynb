{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Transfer Learning\n",
    "_How can we re-use models that have already been trained?_<br>\n",
    "Depending on the task, we may want to salvage other models for parts, perhaps we're expanding functionality or have a similar problem to one we've solved before. Instead of starting from scratch every time, depending on the task, we can use pre-trained models as a starting point and then tweak them to our specific needs.\n",
    "<p>\n",
    "Convolutional NNs are often used for feature extraction, with the layers starting with low level features like edges and shapes, and progressing up to more advanced features. We can simply tune a previously trained model's weights with a new dataset to achieve decent results much faster than retraining from scratch.\n",
    "<p>\n",
    "Typically we will need to train a new classifier, as in most cases we will be using a model to detect new classes and possibly a different amount of total classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Note: majority of pre-trained models from torchvision require images to be 224x224px in size, but other models may have different requirements.* We will also need to perform the same normalisation used when the model was being trained.\n",
    "<br>***Make sure to understand how each model you use actually works and what inputs it requires.***\n",
    "<p>For this model specifically, each color channel was normalised seperately.\n",
    "<br>Means: [0.485, 0.456, 0.406]\n",
    "<br>Standard Deviations: [0.229, 0.224, 0.225]\n",
    "<p> Let's start by loading our data, in this case we will be using Cats and Dogs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "data_dir = \"data/Cat_Dog_data\"\n",
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Resize the data and augment it, then normalise\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(means, stds)\n",
    "])\n",
    "\n",
    "# Resize and normalise\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(means, stds)\n",
    "])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "import os\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=test_transforms)\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=1664, out_features=1000, bias=True)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch offers a variety of pretrained models https://pytorch.org/docs/0.3.0/torchvision/models.html\n",
    "# We will be using one called \"DenseNet\"\n",
    "model = models.densenet169(pretrained=True)\n",
    "# You can take a look at a massive list of information with...\n",
    "model\n",
    "# But the main thing we care about is the number of outputs the model gives,\n",
    "# As that is what we need to pass to a classifier\n",
    "model.classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The DenseNet model was trained using the [ImageNet](https://image-net.org) dataset, which is over 14 million images, although the classifications are not the same, we can use the feature detection part of the model and just attach a new classifier to it.\n",
    "<br>_Note: For image recognition, pre-trained models like this are VERY good at detection features, we should make use of them!_\n",
    "<p>As this model is already sufficient we have no need to adjust it, so we will lock/freeze it by disabling gradient calculation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will make our own classifier for the Cats and Dogs data we are using\n",
    "<br>_Remember: The classifier needs to accept the output of the model!_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# Input size required: 1664\n",
    "cat_dog_classifier = nn.Sequential(OrderedDict([\n",
    "    (\"fc1\", nn.Linear(in_features=1664, out_features=64)),\n",
    "    (\"relu\",nn.ReLU()),\n",
    "    (\"fc2\",nn.Linear(in_features=64, out_features=10)),\n",
    "    (\"output\", nn.LogSoftmax(dim=1)),\n",
    "]))\n",
    "\n",
    "# Overwrite the old classifier\n",
    "model.classifier = cat_dog_classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the new classifier\n",
    "This model is incredibly complex compared to what we are used to, were now at the point where performance and memory usage are pretty important. So we will be using CUDA if available to speed up processing.\n",
    "<br>_The difference can be factors of 100, use whenever possible_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "#torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Recap\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use cuda\n",
    "model = models.densenet169(pretrained=True) # Load a pretrained model\n",
    "for param in model.parameters(): # Freeze the model\n",
    "    param.requires_grad = False\n",
    "model.classifier = cat_dog_classifier # Replace the old classifier\n",
    "criterion = nn.NLLLoss() # Choose a loss function\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003) # Optimise only the classifier\n",
    "model.to(device); # Move it all to the GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "0\n",
      "Step: 1\n",
      "Step: 2\n",
      "Step: 3\n",
      "Step: 4\n",
      "Step: 5\n",
      "Step: 6\n",
      "Step: 7\n",
      "Step: 8\n",
      "Step: 9\n",
      "Step: 10\n",
      "Step: 11\n",
      "Step: 12\n",
      "Step: 13\n",
      "Step: 14\n",
      "Step: 15\n",
      "Step: 16\n",
      "Step: 17\n",
      "Step: 18\n",
      "Step: 19\n",
      "Step: 20\n",
      "Step: 21\n",
      "Step: 22\n",
      "Step: 23\n",
      "Step: 24\n",
      "Step: 25\n",
      "Step: 26\n",
      "Step: 27\n",
      "Step: 28\n",
      "Step: 29\n",
      "Step: 30\n",
      "Step: 31\n",
      "Step: 32\n",
      "Step: 33\n",
      "Step: 34\n",
      "Step: 35\n",
      "Step: 36\n",
      "Step: 37\n",
      "Step: 38\n",
      "Step: 39\n",
      "Step: 40\n",
      "Step: 41\n",
      "Step: 42\n",
      "Step: 43\n",
      "Step: 44\n",
      "Step: 45\n",
      "Step: 46\n",
      "Step: 47\n",
      "Step: 48\n",
      "Step: 49\n",
      "Step: 50\n",
      "~ Changing to evaluation mode\n",
      "Epoch 1/3.. Train loss: 0.071.. Test loss: 0.050.. Test accuracy: 0.982\n",
      "~ Reverting to training mode\n",
      "Step: 51\n",
      "Step: 52\n",
      "Step: 53\n",
      "Step: 54\n",
      "Step: 55\n",
      "Step: 56\n",
      "Step: 57\n",
      "Step: 58\n",
      "Step: 59\n",
      "Step: 60\n",
      "Step: 61\n",
      "Step: 62\n",
      "Step: 63\n",
      "Step: 64\n",
      "Step: 65\n",
      "Step: 66\n",
      "Step: 67\n",
      "Step: 68\n",
      "Step: 69\n",
      "Step: 70\n",
      "Step: 71\n",
      "Step: 72\n",
      "Step: 73\n",
      "Step: 74\n",
      "Step: 75\n",
      "Step: 76\n",
      "Step: 77\n",
      "Step: 78\n",
      "Step: 79\n",
      "Step: 80\n",
      "Step: 81\n",
      "Step: 82\n",
      "Step: 83\n",
      "Step: 84\n",
      "Step: 85\n",
      "Step: 86\n",
      "Step: 87\n",
      "Step: 88\n",
      "Step: 89\n",
      "Step: 90\n",
      "Step: 91\n",
      "Step: 92\n",
      "Step: 93\n",
      "Step: 94\n",
      "Step: 95\n",
      "Step: 96\n",
      "Step: 97\n",
      "Step: 98\n",
      "Step: 99\n",
      "Step: 100\n",
      "~ Changing to evaluation mode\n",
      "Epoch 1/3.. Train loss: 0.084.. Test loss: 0.063.. Test accuracy: 0.979\n",
      "~ Reverting to training mode\n",
      "Step: 101\n",
      "Step: 102\n",
      "Step: 103\n",
      "Step: 104\n",
      "Step: 105\n",
      "Step: 106\n",
      "Step: 107\n",
      "Step: 108\n",
      "Step: 109\n",
      "Step: 110\n",
      "Step: 111\n",
      "Step: 112\n",
      "Step: 113\n",
      "Step: 114\n",
      "Step: 115\n",
      "Step: 116\n",
      "Step: 117\n",
      "Step: 118\n",
      "Step: 119\n",
      "Step: 120\n",
      "Step: 121\n",
      "Step: 122\n",
      "Step: 123\n",
      "Step: 124\n",
      "Step: 125\n",
      "Step: 126\n",
      "Step: 127\n",
      "Step: 128\n",
      "Step: 129\n",
      "Step: 130\n",
      "Step: 131\n",
      "Step: 132\n",
      "Step: 133\n",
      "Step: 134\n",
      "Step: 135\n",
      "Step: 136\n",
      "Step: 137\n",
      "Step: 138\n",
      "Step: 139\n",
      "Step: 140\n",
      "Step: 141\n",
      "Step: 142\n",
      "Step: 143\n",
      "Step: 144\n",
      "Step: 145\n",
      "Step: 146\n",
      "Step: 147\n",
      "Step: 148\n",
      "Step: 149\n",
      "Step: 150\n",
      "~ Changing to evaluation mode\n",
      "Epoch 1/3.. Train loss: 0.080.. Test loss: 0.068.. Test accuracy: 0.976\n",
      "~ Reverting to training mode\n",
      "Step: 151\n",
      "Step: 152\n",
      "Step: 153\n",
      "Step: 154\n",
      "Step: 155\n",
      "Step: 156\n",
      "Step: 157\n",
      "Step: 158\n",
      "Step: 159\n",
      "Step: 160\n",
      "Step: 161\n",
      "Step: 162\n",
      "Step: 163\n",
      "Step: 164\n",
      "Step: 165\n",
      "Step: 166\n",
      "Step: 167\n",
      "Step: 168\n",
      "Step: 169\n",
      "Step: 170\n",
      "Step: 171\n",
      "Step: 172\n",
      "Step: 173\n",
      "Step: 174\n",
      "Step: 175\n",
      "Step: 176\n",
      "Epoch 2\n",
      "176\n",
      "Step: 177\n",
      "Step: 178\n",
      "Step: 179\n",
      "Step: 180\n",
      "Step: 181\n",
      "Step: 182\n",
      "Step: 183\n",
      "Step: 184\n",
      "Step: 185\n",
      "Step: 186\n",
      "Step: 187\n",
      "Step: 188\n",
      "Step: 189\n",
      "Step: 190\n",
      "Step: 191\n",
      "Step: 192\n",
      "Step: 193\n",
      "Step: 194\n",
      "Step: 195\n",
      "Step: 196\n",
      "Step: 197\n",
      "Step: 198\n",
      "Step: 199\n",
      "Step: 200\n",
      "~ Changing to evaluation mode\n",
      "Epoch 2/3.. Train loss: 0.074.. Test loss: 0.042.. Test accuracy: 0.982\n",
      "~ Reverting to training mode\n",
      "Step: 201\n",
      "Step: 202\n",
      "Step: 203\n",
      "Step: 204\n",
      "Step: 205\n",
      "Step: 206\n",
      "Step: 207\n",
      "Step: 208\n",
      "Step: 209\n",
      "Step: 210\n",
      "Step: 211\n",
      "Step: 212\n",
      "Step: 213\n",
      "Step: 214\n",
      "Step: 215\n",
      "Step: 216\n",
      "Step: 217\n",
      "Step: 218\n",
      "Step: 219\n",
      "Step: 220\n",
      "Step: 221\n",
      "Step: 222\n",
      "Step: 223\n",
      "Step: 224\n",
      "Step: 225\n",
      "Step: 226\n",
      "Step: 227\n",
      "Step: 228\n",
      "Step: 229\n",
      "Step: 230\n",
      "Step: 231\n",
      "Step: 232\n",
      "Step: 233\n",
      "Step: 234\n",
      "Step: 235\n",
      "Step: 236\n",
      "Step: 237\n",
      "Step: 238\n",
      "Step: 239\n",
      "Step: 240\n",
      "Step: 241\n",
      "Step: 242\n",
      "Step: 243\n",
      "Step: 244\n",
      "Step: 245\n",
      "Step: 246\n",
      "Step: 247\n",
      "Step: 248\n",
      "Step: 249\n",
      "Step: 250\n",
      "~ Changing to evaluation mode\n",
      "Epoch 2/3.. Train loss: 0.083.. Test loss: 0.040.. Test accuracy: 0.984\n",
      "~ Reverting to training mode\n",
      "Step: 251\n",
      "Step: 252\n",
      "Step: 253\n",
      "Step: 254\n",
      "Step: 255\n",
      "Step: 256\n",
      "Step: 257\n",
      "Step: 258\n",
      "Step: 259\n",
      "Step: 260\n",
      "Step: 261\n",
      "Step: 262\n",
      "Step: 263\n",
      "Step: 264\n",
      "Step: 265\n",
      "Step: 266\n",
      "Step: 267\n",
      "Step: 268\n",
      "Step: 269\n",
      "Step: 270\n",
      "Step: 271\n",
      "Step: 272\n",
      "Step: 273\n",
      "Step: 274\n",
      "Step: 275\n",
      "Step: 276\n",
      "Step: 277\n",
      "Step: 278\n",
      "Step: 279\n",
      "Step: 280\n",
      "Step: 281\n",
      "Step: 282\n",
      "Step: 283\n",
      "Step: 284\n",
      "Step: 285\n",
      "Step: 286\n",
      "Step: 287\n",
      "Step: 288\n",
      "Step: 289\n",
      "Step: 290\n",
      "Step: 291\n",
      "Step: 292\n",
      "Step: 293\n",
      "Step: 294\n",
      "Step: 295\n",
      "Step: 296\n",
      "Step: 297\n",
      "Step: 298\n",
      "Step: 299\n",
      "Step: 300\n",
      "~ Changing to evaluation mode\n",
      "Epoch 2/3.. Train loss: 0.084.. Test loss: 0.045.. Test accuracy: 0.986\n",
      "~ Reverting to training mode\n",
      "Step: 301\n",
      "Step: 302\n",
      "Step: 303\n",
      "Step: 304\n",
      "Step: 305\n",
      "Step: 306\n",
      "Step: 307\n",
      "Step: 308\n",
      "Step: 309\n",
      "Step: 310\n",
      "Step: 311\n",
      "Step: 312\n",
      "Step: 313\n",
      "Step: 314\n",
      "Step: 315\n",
      "Step: 316\n",
      "Step: 317\n",
      "Step: 318\n",
      "Step: 319\n",
      "Step: 320\n",
      "Step: 321\n",
      "Step: 322\n",
      "Step: 323\n",
      "Step: 324\n",
      "Step: 325\n",
      "Step: 326\n",
      "Step: 327\n",
      "Step: 328\n",
      "Step: 329\n",
      "Step: 330\n",
      "Step: 331\n",
      "Step: 332\n",
      "Step: 333\n",
      "Step: 334\n",
      "Step: 335\n",
      "Step: 336\n",
      "Step: 337\n",
      "Step: 338\n",
      "Step: 339\n",
      "Step: 340\n",
      "Step: 341\n",
      "Step: 342\n",
      "Step: 343\n",
      "Step: 344\n",
      "Step: 345\n",
      "Step: 346\n",
      "Step: 347\n",
      "Step: 348\n",
      "Step: 349\n",
      "Step: 350\n",
      "~ Changing to evaluation mode\n",
      "Epoch 2/3.. Train loss: 0.076.. Test loss: 0.054.. Test accuracy: 0.974\n",
      "~ Reverting to training mode\n",
      "Step: 351\n",
      "Step: 352\n",
      "Epoch 3\n",
      "352\n",
      "Step: 353\n",
      "Step: 354\n",
      "Step: 355\n",
      "Step: 356\n",
      "Step: 357\n",
      "Step: 358\n",
      "Step: 359\n",
      "Step: 360\n",
      "Step: 361\n",
      "Step: 362\n",
      "Step: 363\n",
      "Step: 364\n",
      "Step: 365\n",
      "Step: 366\n",
      "Step: 367\n",
      "Step: 368\n",
      "Step: 369\n",
      "Step: 370\n",
      "Step: 371\n",
      "Step: 372\n",
      "Step: 373\n",
      "Step: 374\n",
      "Step: 375\n",
      "Step: 376\n",
      "Step: 377\n",
      "Step: 378\n",
      "Step: 379\n",
      "Step: 380\n",
      "Step: 381\n",
      "Step: 382\n",
      "Step: 383\n",
      "Step: 384\n",
      "Step: 385\n",
      "Step: 386\n",
      "Step: 387\n",
      "Step: 388\n",
      "Step: 389\n",
      "Step: 390\n",
      "Step: 391\n",
      "Step: 392\n",
      "Step: 393\n",
      "Step: 394\n",
      "Step: 395\n",
      "Step: 396\n",
      "Step: 397\n",
      "Step: 398\n",
      "Step: 399\n",
      "Step: 400\n",
      "~ Changing to evaluation mode\n",
      "Epoch 3/3.. Train loss: 0.075.. Test loss: 0.080.. Test accuracy: 0.968\n",
      "~ Reverting to training mode\n",
      "Step: 401\n",
      "Step: 402\n",
      "Step: 403\n",
      "Step: 404\n",
      "Step: 405\n",
      "Step: 406\n",
      "Step: 407\n",
      "Step: 408\n",
      "Step: 409\n",
      "Step: 410\n",
      "Step: 411\n",
      "Step: 412\n",
      "Step: 413\n",
      "Step: 414\n",
      "Step: 415\n",
      "Step: 416\n",
      "Step: 417\n",
      "Step: 418\n",
      "Step: 419\n",
      "Step: 420\n",
      "Step: 421\n",
      "Step: 422\n",
      "Step: 423\n",
      "Step: 424\n",
      "Step: 425\n",
      "Step: 426\n",
      "Step: 427\n",
      "Step: 428\n",
      "Step: 429\n",
      "Step: 430\n",
      "Step: 431\n",
      "Step: 432\n",
      "Step: 433\n",
      "Step: 434\n",
      "Step: 435\n",
      "Step: 436\n",
      "Step: 437\n",
      "Step: 438\n",
      "Step: 439\n",
      "Step: 440\n",
      "Step: 441\n",
      "Step: 442\n",
      "Step: 443\n",
      "Step: 444\n",
      "Step: 445\n",
      "Step: 446\n",
      "Step: 447\n",
      "Step: 448\n",
      "Step: 449\n",
      "Step: 450\n",
      "~ Changing to evaluation mode\n",
      "Epoch 3/3.. Train loss: 0.056.. Test loss: 0.040.. Test accuracy: 0.988\n",
      "~ Reverting to training mode\n",
      "Step: 451\n",
      "Step: 452\n",
      "Step: 453\n",
      "Step: 454\n",
      "Step: 455\n",
      "Step: 456\n",
      "Step: 457\n",
      "Step: 458\n",
      "Step: 459\n",
      "Step: 460\n",
      "Step: 461\n",
      "Step: 462\n",
      "Step: 463\n",
      "Step: 464\n",
      "Step: 465\n",
      "Step: 466\n",
      "Step: 467\n",
      "Step: 468\n",
      "Step: 469\n",
      "Step: 470\n",
      "Step: 471\n",
      "Step: 472\n",
      "Step: 473\n",
      "Step: 474\n",
      "Step: 475\n",
      "Step: 476\n",
      "Step: 477\n",
      "Step: 478\n",
      "Step: 479\n",
      "Step: 480\n",
      "Step: 481\n",
      "Step: 482\n",
      "Step: 483\n",
      "Step: 484\n",
      "Step: 485\n",
      "Step: 486\n",
      "Step: 487\n",
      "Step: 488\n",
      "Step: 489\n",
      "Step: 490\n",
      "Step: 491\n",
      "Step: 492\n",
      "Step: 493\n",
      "Step: 494\n",
      "Step: 495\n",
      "Step: 496\n",
      "Step: 497\n",
      "Step: 498\n",
      "Step: 499\n",
      "Step: 500\n",
      "~ Changing to evaluation mode\n",
      "Epoch 3/3.. Train loss: 0.064.. Test loss: 0.044.. Test accuracy: 0.988\n",
      "~ Reverting to training mode\n",
      "Step: 501\n",
      "Step: 502\n",
      "Step: 503\n",
      "Step: 504\n",
      "Step: 505\n",
      "Step: 506\n",
      "Step: 507\n",
      "Step: 508\n",
      "Step: 509\n",
      "Step: 510\n",
      "Step: 511\n",
      "Step: 512\n",
      "Step: 513\n",
      "Step: 514\n",
      "Step: 515\n",
      "Step: 516\n",
      "Step: 517\n",
      "Step: 518\n",
      "Step: 519\n",
      "Step: 520\n",
      "Step: 521\n",
      "Step: 522\n",
      "Step: 523\n",
      "Step: 524\n",
      "Step: 525\n",
      "Step: 526\n",
      "Step: 527\n",
      "Step: 528\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 50\n",
    "max_accuracy = 0\n",
    "accuracy_results = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(steps)\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        print(f\"Step: {steps}\")\n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # write the training loop. call the loss \"loss\" so that the line below will work\n",
    "        #print(\"> Making predictions\")\n",
    "        predictions = model(inputs)\n",
    "        #print(\"> Calculating loss\")\n",
    "        loss = criterion(predictions, labels)\n",
    "        #print(\"> Backpropogating\")# Compute the loss\n",
    "        loss.backward()\n",
    "        #print(\"> Stepping\")# Backpropogate\n",
    "        optimizer.step()\n",
    "        #print(\"> Resetting gradients\")# Update the parameters (weights and biases)\n",
    "        optimizer.zero_grad() # Reset gradients\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        #print(f\"> Running loss: {running_loss}\")\n",
    "\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            print(\"~ Changing to evaluation mode\")\n",
    "            model.eval()\n",
    "            # ...\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "\n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    # Save the best model\n",
    "                    if accuracy >= max_accuracy:\n",
    "                        max_accuracy = accuracy\n",
    "                        torch.save(model.state_dict(), 'catordog.epic')\n",
    "\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            accuracy_results.append([steps, accuracy/len(testloader)])\n",
    "            running_loss = 0\n",
    "            print(\"~ Reverting to training mode\")\n",
    "            model.train()\n",
    "            # REMEMBER TO REACTIVATE THE TRAIN MODE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ Step 50: 0.9820772051811218 accuracy\n",
      "@ Step 100: 0.9786075353622437 accuracy\n",
      "@ Step 150: 0.9763097435235977 accuracy\n",
      "@ Step 200: 0.98203125 accuracy\n",
      "@ Step 250: 0.983984375 accuracy\n",
      "@ Step 300: 0.9859834551811218 accuracy\n",
      "@ Step 350: 0.973828125 accuracy\n",
      "@ Step 400: 0.9684972435235977 accuracy\n",
      "@ Step 450: 0.9875459551811219 accuracy\n",
      "@ Step 500: 0.9875459551811219 accuracy\n"
     ]
    }
   ],
   "source": [
    "for step, result in accuracy_results:\n",
    "    print(f\"@ Step {step}: {result} accuracy\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}